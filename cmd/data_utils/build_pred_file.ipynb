{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build prediction file \n",
    "\n",
    "Builds the prediction file as expected for the evaluation :\n",
    "file : tab format with 3 columns : file_name, MeSH_Label, description \n",
    "\n",
    "\n",
    "(Prend en entrée la référence (classes-train-v2.txt) et l'hypothèse\n",
    "(sortie-system). Les deux fichiers sont au format tabulaire en trois\n",
    "colonnes : nom du fichier, nom simplifié du chapitre du MeSH, un\n",
    "exemple issu du texte pour ce chapitre et ce fichier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import isfile, isdir, join, basename\n",
    "from os import listdir\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "import math\n",
    "from sklearn import metrics\n",
    "\n",
    "IN_BRAT_DIR = '../../data/release/train2021/'\n",
    "OUT_DIR = '../../data/release/train2021/'\n",
    "\n",
    "IN_TRAIN_FILE = '../../data/work/classes-train-train.txt'\n",
    "IN_DEV_FILE = '../../data/work/classes-train-val.txt'\n",
    "IN_FR_MESH_FILE = '../../resources/terminologie_MeSH_DEFT2021.xlsx'\n",
    "\n",
    "OUT_DF = '../../data/mesh_term_dataset.pkl'\n",
    "\n",
    "assert isdir(IN_BRAT_DIR)\n",
    "assert isfile(IN_TRAIN_FILE)\n",
    "assert isfile(IN_FR_MESH_FILE)\n",
    "assert isfile(IN_DEV_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ORL',\n",
       " 'blessures',\n",
       " 'cardiovasculaires',\n",
       " 'chimiques',\n",
       " 'digestif',\n",
       " 'endocriniennes',\n",
       " 'etatsosy',\n",
       " 'femme',\n",
       " 'genetique',\n",
       " 'hemopathies',\n",
       " 'homme',\n",
       " 'immunitaire',\n",
       " 'infections',\n",
       " 'nerveux',\n",
       " 'nutritionnelles',\n",
       " 'oeil',\n",
       " 'osteomusculaires',\n",
       " 'parasitaires',\n",
       " 'peau',\n",
       " 'respiratoire',\n",
       " 'stomatognathique',\n",
       " 'tumeur',\n",
       " 'virales'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read all Brat files in Brat dir and keep the MeSH corresponding labels\n",
    "\n",
    "# first extract the set of labels\n",
    "deft_dfs = {}\n",
    "labels = set()\n",
    "for source, f in zip(['DEFT-train', 'DEFT-val'], [IN_TRAIN_FILE, IN_DEV_FILE]):\n",
    "    labels_df = pd.read_csv(f, sep='\\t', header=None, names=['file', 'label', 'desc'])\n",
    "    labels |= set(labels_df['label'].unique())\n",
    "    files = labels_df['file'].unique()\n",
    "    deft_dfs[source] = (labels_df, files)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENTITY_REGEX = re.compile('^(T\\d+)\\t([^ ]+) ([^\\t]+)\\t(.*)$')\n",
    "\n",
    "data = []\n",
    "# extract all ann_files from IN_BRAT_DIR\n",
    "ann_files = [f for f in listdir(IN_BRAT_DIR) if isfile(join(IN_BRAT_DIR, f)) if f.endswith('.ann')]\n",
    "\n",
    "\n",
    "with open(\"test.txt\", \"w+\") as filout:\n",
    "    for ann_file in ann_files:\n",
    "        ann_path = join(IN_BRAT_DIR, ann_file)\n",
    "        assert isfile(ann_path)\n",
    "        # Read ann file\n",
    "        with open(ann_path, 'r', encoding='utf-8') as f_in:\n",
    "            lines = f_in.readlines()\n",
    "    \n",
    "        columns = ['term', 'label', 'source']\n",
    "\n",
    "        # First pass -> extract all labels (i.e entity with Mesh-like tags)\n",
    "        label_infos = {}\n",
    "        other_infos = {}\n",
    "        for line in lines:\n",
    "            entity_match = ENTITY_REGEX.match(line.strip())\n",
    "            if entity_match is not None:\n",
    "                ann_id = entity_match.group(1)\n",
    "                label = entity_match.group(2)\n",
    "                offsets = entity_match.group(3)\n",
    "                span = entity_match.group(4)\n",
    "                if label in labels:\n",
    "                    label_list = label_infos.get(offsets, [])\n",
    "                    label_list.append((ann_id, label, offsets, span))\n",
    "                    label_infos[offsets] = label_list\n",
    "                    data.append([basename(ann_path), label, span])\n",
    "                    that_line = [basename(ann_path), label, span]\n",
    "                    that_line_txt = \"\\t\".join(that_line) \n",
    "                    filout.write(\"{}\\n\".format(that_line_txt))\n",
    "\n",
    "                    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
